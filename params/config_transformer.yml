##############################
# Config for transformer models
##############################

dataset:
  time_list: [9, 12, 15, 18]  # hours; list or 'all'. If 'all', use all hours. The current list = [9, 12, 15, 18]
  train_start: "2016-01-01"  # the start date of the train data; date or 'first'
  train_end: "2021-12-31"  # the end date of the train data; date
  valid_start: "2022-01-01"  # the start date of the validation data; date
  valid_end: "2022-12-31"  # the end date of the validation data; date
  test_start: "2023-01-01"  # the start date of the test data; date
  test_end: "2023-09-30"  # the end date of the test data; date or 'last'
  seq_len_src: 28  # = (num of timestamps in 1 day) * (days); int
  seq_len_tgt: 4  # = (num of timestamps in 1 day) * (days); int
  lag_len: 4  # the nun of lag length in train dataset; int
  batch_size: 128  # the num of batch size; int

model:
  nhead: 3  # (d_model % nhead) needs to be 0; int. The current d_model = 66
  dim_feedforward: 512  # default = 2048; int
  num_encoder_layers: 3  # default = 6; int
  num_decoder_layers: 3  # default = 6; int
  dropout: 0.3  # float

training:
  n_epochs: 800  # int
  learning_rate: 0.1  # initial learning rate; float
  milestones: [10, 30, 40, 400]  # for scheduler; list
  gamma: 0.1  # for scheduler; float
  num_features_pred: 10  # the num of features to be used for prediction. Currently, 10 locations