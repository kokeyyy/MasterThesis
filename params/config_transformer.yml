##############################
# Config for transformer models
##############################

dataset:
  time_list: [9, 12, 15, 18, 21]   # hours; list or 'all'. If 'all', use all hours. The current list = [9, 12, 15, 18]
  train_start: "2016-01-01"  # the start date of the train data; date or 'first'
  train_end: "2023-06-30"  # the end date of the train data; date
  valid_start: "2022-01-01"  # the start date of the validation data; date
  valid_end: "2022-12-31"  # the end date of the validation data; date
  test_start: "2023-07-01"  # the start date of the test data; date
  test_end: "2023-09-30"  # the end date of the train data; date or 'last'
  seq_len_src: 5  # = (num of timestamps in 1 day) * (days) = 8 periods * 1 day; int
  seq_len_tgt: 5  # = (num of timestamps in 1 day) * (days) = 8 periods * 1 day; int
  batch_size: 64  # the num of batch size. len(train_dataset)=1368; int

model:
  nhead: 6  # (d_model % nhead) needs to be 0; int.  Current d_model = 66
  dim_feedforward: 1024  # default = 2048; int
  num_encoder_layers: 5 # default = 6; int
  num_decoder_layers: 5  # default = 6; int
  dropout: 0.2  # float

training:
  n_epochs: 1300  # int
  learning_rate: 0.0005  # float
  num_features_pred: 10  # the num of features to be used for prediction. Currently, 10 locations
  loss_calculation: 'features_pred'  # 'features_pred' or 'all'